{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Metadata\n",
    "\n",
    "```\n",
    "Course:   DS 5001\n",
    "Module:   12 Lab\n",
    "Topic:    Save Novels with Emotions \n",
    "Author:   R.C. Alvarado\n",
    "\n",
    "Purpose:  Collect all the novel collections we have and combine each novel with the combined sentiment lexicon table we created last time.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set Up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_home = \"../data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    'novels': {\n",
    "        'OHCO': 'book_id chap_id para_num sent_num token_num'.split(),\n",
    "        'LIB': 'LIB',\n",
    "        'TOKENS': 'CORPUS',\n",
    "        'path': 'novels'\n",
    "    },\n",
    "    'austen-melville': {\n",
    "        'OHCO': 'book_id chap_id para_num sent_num token_num'.split(),\n",
    "        'LIB': 'LIB2',\n",
    "        'TOKENS': 'CORPUS2',\n",
    "        'path': 'output'\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "token_cols = ['pos','term_str']\n",
    "salex_csv = f'{data_home}/salex/salex_combo.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Lexicons\n",
    "\n",
    "We created this last week."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "SALEX = pd.read_csv(salex_csv).set_index('term_str')\n",
    "SALEX['nrc_polarity'] = SALEX.nrc_positive - SALEX.nrc_negative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['nrc_anger',\n",
       " 'nrc_anticipation',\n",
       " 'nrc_disgust',\n",
       " 'nrc_fear',\n",
       " 'nrc_joy',\n",
       " 'nrc_negative',\n",
       " 'nrc_positive',\n",
       " 'nrc_sadness',\n",
       " 'nrc_surprise',\n",
       " 'nrc_trust',\n",
       " 'nrc_polarity',\n",
       " 'bing_negative',\n",
       " 'bing_positive',\n",
       " 'bing_sentiment',\n",
       " 'syu_sentiment',\n",
       " 'gi_sentiment',\n",
       " 'labmt_happiness',\n",
       " 'labmt_z']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SALEX.columns.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Texts\n",
    "\n",
    "We import two sets of pre-processed novels and combine them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../data/novels/novels-CORPUS.csv\n",
      "../data/output/austen-melville-CORPUS2.csv\n"
     ]
    }
   ],
   "source": [
    "TOKENS = {} # Dict of dataframes\n",
    "LIB = {} # Dict of dataframes\n",
    "for prefix in config:\n",
    "    path = config[prefix]['path']\n",
    "\n",
    "    token_file = f\"{data_home}/{path}/{prefix}-{config[prefix]['TOKENS']}.csv\"\n",
    "    print(token_file)\n",
    "    TOKENS[prefix] = pd.read_csv(token_file).set_index(config[prefix]['OHCO'])[token_cols]\n",
    "    \n",
    "    lib_file = f\"{data_home}/{path}/{prefix}-{config[prefix]['LIB']}.csv\"\n",
    "    LIB[prefix] = pd.read_csv(lib_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Standardize the two `LIB` tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "LIB['novels']['title'] = LIB['novels']['book_id'].str.upper()\n",
    "LIB['novels'] = LIB['novels'].set_index('book_id')\n",
    "LIB['novels'] = LIB['novels'][['author_id', 'title']]\n",
    "LIB['novels']['corpus'] = 'novels' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LIB['novels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "LIB['austen-melville'] = LIB['austen-melville'].set_index('book_id')\n",
    "LIB['austen-melville'] = LIB['austen-melville'][['author', 'title']]\n",
    "LIB['austen-melville']['corpus'] = 'austen-melville'\n",
    "LIB['austen-melville']['author_id'] = LIB['austen-melville'].author.apply(lambda x: x.split(',')[0].lower())\n",
    "LIB['austen-melville'] = LIB['austen-melville'].drop(['author'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LIB['austen-melville']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Concat into one LIB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "LIB_ALL = pd.concat([LIB[prefix] for prefix in config])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author_id</th>\n",
       "      <th>title</th>\n",
       "      <th>corpus</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>book_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>austen</td>\n",
       "      <td>MANSFIELD PARK</td>\n",
       "      <td>austen-melville</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>946</th>\n",
       "      <td>austen</td>\n",
       "      <td>LADY SUSAN</td>\n",
       "      <td>austen-melville</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15422</th>\n",
       "      <td>melville</td>\n",
       "      <td>ISRAEL POTTER HIS FI</td>\n",
       "      <td>austen-melville</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>usher</th>\n",
       "      <td>poe</td>\n",
       "      <td>USHER</td>\n",
       "      <td>novels</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>frankenstein</th>\n",
       "      <td>shelley</td>\n",
       "      <td>FRANKENSTEIN</td>\n",
       "      <td>novels</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>adventures</th>\n",
       "      <td>doyle</td>\n",
       "      <td>ADVENTURES</td>\n",
       "      <td>novels</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>scarlet</th>\n",
       "      <td>doyle</td>\n",
       "      <td>SCARLET</td>\n",
       "      <td>novels</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pitandpendulum</th>\n",
       "      <td>poe</td>\n",
       "      <td>PITANDPENDULUM</td>\n",
       "      <td>novels</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161</th>\n",
       "      <td>austen</td>\n",
       "      <td>SENSE AND SENSIBILIT</td>\n",
       "      <td>austen-melville</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>austen</td>\n",
       "      <td>EMMA</td>\n",
       "      <td>austen-melville</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               author_id                 title           corpus\n",
       "book_id                                                        \n",
       "141               austen        MANSFIELD PARK  austen-melville\n",
       "946               austen            LADY SUSAN  austen-melville\n",
       "15422           melville  ISRAEL POTTER HIS FI  austen-melville\n",
       "usher                poe                 USHER           novels\n",
       "frankenstein     shelley          FRANKENSTEIN           novels\n",
       "adventures         doyle            ADVENTURES           novels\n",
       "scarlet            doyle               SCARLET           novels\n",
       "pitandpendulum       poe        PITANDPENDULUM           novels\n",
       "161               austen  SENSE AND SENSIBILIT  austen-melville\n",
       "158               austen                  EMMA  austen-melville"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LIB_ALL.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combine into one TOKENS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "TOKENS_ALL = pd.concat([TOKENS[prefix] for prefix in config])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>pos</th>\n",
       "      <th>term_str</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>book_id</th>\n",
       "      <th>chap_id</th>\n",
       "      <th>para_num</th>\n",
       "      <th>sent_num</th>\n",
       "      <th>token_num</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">secretadversary</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">1</th>\n",
       "      <th rowspan=\"4\" valign=\"top\">0</th>\n",
       "      <th rowspan=\"4\" valign=\"top\">1</th>\n",
       "      <th>0</th>\n",
       "      <td>DT</td>\n",
       "      <td>the</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NNP</td>\n",
       "      <td>young</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NNP</td>\n",
       "      <td>adventurers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NNP</td>\n",
       "      <td>ltd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <td>JJ</td>\n",
       "      <td>tommy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">34970</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">114</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">24</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">0</th>\n",
       "      <th>6</th>\n",
       "      <td>DT</td>\n",
       "      <td>the</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>NNP</td>\n",
       "      <td>ambiguities</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>IN</td>\n",
       "      <td>by</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>NNP</td>\n",
       "      <td>herman</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>NNP</td>\n",
       "      <td>melville</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3484453 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     pos     term_str\n",
       "book_id         chap_id para_num sent_num token_num                  \n",
       "secretadversary 1       0        1        0           DT          the\n",
       "                                          1          NNP        young\n",
       "                                          2          NNP  adventurers\n",
       "                                          3          NNP          ltd\n",
       "                        1        0        0           JJ        tommy\n",
       "...                                                  ...          ...\n",
       "34970           114     24       0        6           DT          the\n",
       "                                          7          NNP  ambiguities\n",
       "                                          8           IN           by\n",
       "                                          9          NNP       herman\n",
       "                                          10         NNP     melville\n",
       "\n",
       "[3484453 rows x 2 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TOKENS_ALL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge with SALEX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "TOKENS_SENT = TOKENS_ALL.reset_index().merge(SALEX, on='term_str', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>book_id</th>\n",
       "      <th>chap_id</th>\n",
       "      <th>para_num</th>\n",
       "      <th>sent_num</th>\n",
       "      <th>token_num</th>\n",
       "      <th>pos</th>\n",
       "      <th>term_str</th>\n",
       "      <th>nrc_anger</th>\n",
       "      <th>nrc_anticipation</th>\n",
       "      <th>nrc_disgust</th>\n",
       "      <th>...</th>\n",
       "      <th>nrc_surprise</th>\n",
       "      <th>nrc_trust</th>\n",
       "      <th>nrc_polarity</th>\n",
       "      <th>bing_negative</th>\n",
       "      <th>bing_positive</th>\n",
       "      <th>bing_sentiment</th>\n",
       "      <th>syu_sentiment</th>\n",
       "      <th>gi_sentiment</th>\n",
       "      <th>labmt_happiness</th>\n",
       "      <th>labmt_z</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2144262</th>\n",
       "      <td>1212</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>67</td>\n",
       "      <td>NN</td>\n",
       "      <td>intimacy</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1664966</th>\n",
       "      <td>141</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>24</td>\n",
       "      <td>JJS</td>\n",
       "      <td>least</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.00</td>\n",
       "      <td>-2.267613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3238649</th>\n",
       "      <td>21816</td>\n",
       "      <td>48</td>\n",
       "      <td>32</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>JJ</td>\n",
       "      <td>such</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.16</td>\n",
       "      <td>-1.198395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2395211</th>\n",
       "      <td>2701</td>\n",
       "      <td>4</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>NNS</td>\n",
       "      <td>gates</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.28</td>\n",
       "      <td>-1.087786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1793842</th>\n",
       "      <td>141</td>\n",
       "      <td>39</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>47</td>\n",
       "      <td>DT</td>\n",
       "      <td>no</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.48</td>\n",
       "      <td>-2.746918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2757020</th>\n",
       "      <td>8118</td>\n",
       "      <td>88</td>\n",
       "      <td>23</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>IN</td>\n",
       "      <td>than</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.74</td>\n",
       "      <td>-1.585526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>754698</th>\n",
       "      <td>monk</td>\n",
       "      <td>5</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>NN</td>\n",
       "      <td>crimson</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.00</td>\n",
       "      <td>-0.424133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2213677</th>\n",
       "      <td>1342</td>\n",
       "      <td>31</td>\n",
       "      <td>23</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>NN</td>\n",
       "      <td>trouble</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>2.78</td>\n",
       "      <td>-3.392136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599695</th>\n",
       "      <td>121</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>VBD</td>\n",
       "      <td>said</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.38</td>\n",
       "      <td>-0.995612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1597496</th>\n",
       "      <td>121</td>\n",
       "      <td>8</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>CC</td>\n",
       "      <td>and</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.22</td>\n",
       "      <td>-1.143091</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        book_id  chap_id  para_num  sent_num  token_num  pos  term_str  \\\n",
       "2144262    1212       17         0         5         67   NN  intimacy   \n",
       "1664966     141        2         2         0         24  JJS     least   \n",
       "3238649   21816       48        32         3          4   JJ      such   \n",
       "2395211    2701        4        17         0         14  NNS     gates   \n",
       "1793842     141       39        11         0         47   DT        no   \n",
       "2757020    8118       88        23         2          9   IN      than   \n",
       "754698     monk        5        14         0          6   NN   crimson   \n",
       "2213677    1342       31        23         1          9   NN   trouble   \n",
       "1599695     121        9         4         0          2  VBD      said   \n",
       "1597496     121        8        10         1         11   CC       and   \n",
       "\n",
       "         nrc_anger  nrc_anticipation  nrc_disgust  ...  nrc_surprise  \\\n",
       "2144262        NaN               NaN          NaN  ...           NaN   \n",
       "1664966        NaN               NaN          NaN  ...           NaN   \n",
       "3238649        NaN               NaN          NaN  ...           NaN   \n",
       "2395211        NaN               NaN          NaN  ...           NaN   \n",
       "1793842        NaN               NaN          NaN  ...           NaN   \n",
       "2757020        NaN               NaN          NaN  ...           NaN   \n",
       "754698         NaN               NaN          NaN  ...           NaN   \n",
       "2213677        NaN               NaN          NaN  ...           NaN   \n",
       "1599695        NaN               NaN          NaN  ...           NaN   \n",
       "1597496        NaN               NaN          NaN  ...           NaN   \n",
       "\n",
       "         nrc_trust  nrc_polarity  bing_negative  bing_positive  \\\n",
       "2144262        NaN           NaN            0.0            1.0   \n",
       "1664966        NaN           NaN            NaN            NaN   \n",
       "3238649        NaN           NaN            NaN            NaN   \n",
       "2395211        NaN           NaN            NaN            NaN   \n",
       "1793842        NaN           NaN            NaN            NaN   \n",
       "2757020        NaN           NaN            NaN            NaN   \n",
       "754698         NaN           NaN            NaN            NaN   \n",
       "2213677        NaN           NaN            1.0            0.0   \n",
       "1599695        NaN           NaN            NaN            NaN   \n",
       "1597496        NaN           NaN            NaN            NaN   \n",
       "\n",
       "         bing_sentiment  syu_sentiment  gi_sentiment  labmt_happiness  \\\n",
       "2144262             1.0            0.8           1.0              NaN   \n",
       "1664966             NaN            NaN           NaN             4.00   \n",
       "3238649             NaN            NaN           NaN             5.16   \n",
       "2395211             NaN            NaN           NaN             5.28   \n",
       "1793842             NaN            NaN           NaN             3.48   \n",
       "2757020             NaN            NaN           NaN             4.74   \n",
       "754698              NaN            NaN           NaN             6.00   \n",
       "2213677            -1.0           -0.5          -1.0             2.78   \n",
       "1599695             NaN            NaN           NaN             5.38   \n",
       "1597496             NaN            NaN           NaN             5.22   \n",
       "\n",
       "          labmt_z  \n",
       "2144262       NaN  \n",
       "1664966 -2.267613  \n",
       "3238649 -1.198395  \n",
       "2395211 -1.087786  \n",
       "1793842 -2.746918  \n",
       "2757020 -1.585526  \n",
       "754698  -0.424133  \n",
       "2213677 -3.392136  \n",
       "1599695 -0.995612  \n",
       "1597496 -1.143091  \n",
       "\n",
       "[10 rows x 25 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TOKENS_SENT.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export to Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "LIB_ALL.to_csv(f\"{data_home}/combo/combo-LIB.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "novels-secretadversary.csv\n",
      "novels-styles.csv\n",
      "novels-moonstone.csv\n",
      "novels-adventures.csv\n",
      "novels-baskervilles.csv\n",
      "novels-scarlet.csv\n",
      "novels-signoffour.csv\n",
      "novels-marieroget.csv\n",
      "novels-ruemorgue.csv\n",
      "novels-northangerabbey.csv\n",
      "novels-christmascarole.csv\n",
      "novels-monk.csv\n",
      "novels-pitandpendulum.csv\n",
      "novels-reddeath.csv\n",
      "novels-usher.csv\n",
      "novels-udolpho.csv\n",
      "novels-oldenglishbaron.csv\n",
      "novels-frankenstein.csv\n",
      "novels-dracula.csv\n",
      "novels-castleofotranto.csv\n",
      "austen-melville-105.csv\n",
      "austen-melville-121.csv\n",
      "austen-melville-141.csv\n",
      "austen-melville-158.csv\n",
      "austen-melville-161.csv\n",
      "austen-melville-946.csv\n",
      "austen-melville-1212.csv\n",
      "austen-melville-1342.csv\n",
      "austen-melville-1900.csv\n",
      "austen-melville-2701.csv\n",
      "austen-melville-4045.csv\n",
      "austen-melville-8118.csv\n",
      "austen-melville-10712.csv\n",
      "austen-melville-13720.csv\n",
      "austen-melville-13721.csv\n",
      "austen-melville-15422.csv\n",
      "austen-melville-21816.csv\n",
      "austen-melville-34970.csv\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "for book_id in LIB_ALL.index:\n",
    "    corpus = LIB_ALL.loc[book_id].corpus\n",
    "    filename = '-'.join([corpus, str(book_id)]) + '.csv'\n",
    "    print(filename)\n",
    "    cols = TOKENS_SENT.columns[1:]\n",
    "    TOKENS_SENT.loc[TOKENS_SENT.book_id == book_id, cols].to_csv(f\"{data_home}/combo/{filename}\", index=False)\n",
    "print(\"Done.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
